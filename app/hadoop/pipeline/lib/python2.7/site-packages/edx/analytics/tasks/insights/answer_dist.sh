#!/bin/bash
#working but not update
source /edx/app/hadoop/hadoop/etc/hadoop/hadoop-env.sh
source /edx/app/hadoop/hive/conf/hive-env.sh
source /edx/app/hadoop/sqoop/conf/sqoop-env.sh

source /edx/app/hadoop/pipeline/bin/activate


PYTHONPATH='/edx/app/hadoop/pipeline/local/lib/python2.7/site-packages/edx/analytics/tasks/insights/' luigi --module answer_dist \
AnswerDistributionWorkflow \
--mapreduce-engine hadoop \
--remote-log-level "DEBUG" \
--database reports \
--credentials "/edx/etc/edx-analytics-pipeline/output.json" \
--name answer \
--src '["hdfs://localhost:9000/data"]' \
--dest "hdfs://localhost:9000/tmp/pipeline-task-scheduler/AnswerDistributionWorkflow" \
--overwrite \
--output-root 'hdfs://localhost:9000/edx-analytics-pipeline/event-export-by-course/output/' \
--marker "hdfs://localhost:9000/edx-analytics-pipeline/marker/" \
--include '[".*tracking.log.*",".*tracking.log-([0-9]+)-([0-9]).gz.*"]'

#AnswerDistributionPerCourseMixin \

#ProblemCheckEventMixin \
