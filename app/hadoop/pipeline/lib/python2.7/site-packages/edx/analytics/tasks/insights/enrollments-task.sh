#!/bin/bash
source /edx/app/hadoop/hadoop/etc/hadoop/hadoop-env.sh
source /edx/app/hadoop/hive/conf/hive-env.sh
source /edx/app/hadoop/sqoop/conf/sqoop-env.sh


source /edx/app/hadoop/pipeline/bin/activate

intervalstart='2017-04-01'
interval=2019-04-01-$(date +%Y-%m-%d)
overwritendays='2'
nreducetask='25'
pattern='[".*tracking.log.*",".*tracking.log-([0-9]+)-([0-9]).gz.*"]'

PYTHONPATH='/edx/app/hadoop/pipeline/local/lib/python2.7/site-packages/edx/analytics/tasks/insights' luigi   \
--module enrollments CourseEnrollmentTask \
--interval $interval \
--source '["hdfs://localhost:9000/data/"]' \
--pattern $pattern \
--warehouse-path 'hdfs://localhost:9000/edx-analytics-pipeline/warehouse'  \
--n-reduce-task $nreducetask \
--overwrite-n-days $overwritendays \
--mapreduce-engine "hadoop" \
--remote-log-level "DEBUG" \
--output-root 'hdfs://localhost:9000/edx-analytics-pipeline/event-export-by-course/output/'

