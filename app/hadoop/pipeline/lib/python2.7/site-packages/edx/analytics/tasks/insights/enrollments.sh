#!/bin/bash

source /edx/app/hadoop/hadoop/etc/hadoop/hadoop-env.sh
source /edx/app/hadoop/hive/conf/hive-env.sh
source /edx/app/hadoop/sqoop/conf/sqoop-env.sh

source /edx/app/hadoop/pipeline/bin/activate
#cd /edx/app/hadoop/pipeline/local/lib/python2.7/site-packages/edx/analytics/tasks/insights/

#CourseMetaSummaryEnrollmentDataTask \ not working
#list=("ImportEnrollmentsIntoMysql" "CourseEnrollmentEventsTask" "CourseEnrollmentTask" "CourseMetaSummaryEnrollmentTableTask" "CourseMetaSummaryEnrollmentPartitionTask" "CourseMetaSummaryEnrollmentDataTask" "CourseMetaSummaryEnrollmentIntoMysql" "DaysEnrolledForEvents" "ExternalCourseEnrollmentPartitionTask" "CourseEnrollmentSummaryTask" "CourseEnrollmentSummaryTableTask" "CourseEnrollmentSummaryPartitionTask" "EnrollmentByGenderHiveTableTask" "EnrollmentByGenderHiveTableTask" "EnrollmentByGenderHivePartitionTask" "EnrollmentByGenderDataTask" "EnrollmentByGenderMysqlTask" "EnrollmentByBirthYearTaskTableTask" "EnrollmentByBirthYearPartitionTask" "EnrollmentByBirthYearDataTask" "EnrollmentByBirthYearToMysqlTask" "EnrollmentByEducationLevelTableTask" "EnrollmentByEducationLevelPartitionTask" "EnrollmentByEducationLevelDataTask" "EnrollmentByEducationLevelMysqlTask" "EnrollmentByModeTableTask" "EnrollmentByModePartitionTask" "EnrollmentByModeDataTask" "EnrollmentByModeDataTask" "EnrollmentByModeTask" "EnrollmentDailyTableTask" "EnrollmentDailyPartitionTask" "EnrollmentDailyDataTask" "EnrollmentDailyMysqlTask" "CourseProgramMetadataTableTask" "CourseProgramMetadataPartitionTask" "CourseProgramMetadataDataTask" "CourseProgramMetadataInsertToMysqlTask" "CourseGradeByModeTableTask" "CourseGradeByModePartitionTask" "CourseGradeByModeDataTask" )


intervalstart=2017-04-01
currentdate=2017-04-01-$(date +%Y-%m-%d)
#currentdate=2017-04-01-2019-06-03
overwritendays=2
nreducetask=25
pattern='[".*tracking.log.*",".*tracking.log-([0-9]+)-([0-9]).gz.*"]'

PYTHONPATH='/edx/app/hadoop/pipeline/local/lib/python2.7/site-packages/edx/analytics/tasks/insights/' \
luigi --module enrollments ImportEnrollmentsIntoMysql \
--interval-start '2017-04-01' \
--interval $currentdate \
--remote-log-level "DEBUG" \
--source '["hdfs://localhost:9000/data"]' \
--pattern $pattern \
--warehouse-path 'hdfs://localhost:9000/edx-analytics-pipeline/warehouse'  \
--overwrite-n-days $overwritendays \
--n-reduce-task $nreducetask \
--mapreduce-engine "hadoop" \
--overwrite 

sleep 10

PYTHONPATH='/edx/app/hadoop/pipeline/local/lib/python2.7/site-packages/edx/analytics/tasks/insights/' \
luigi --module enrollments CourseMetaSummaryEnrollmentIntoMysql  \
--interval $currentdate \
--source '["hdfs://localhost:9000/data"]' \
--pattern $pattern \
--warehouse-path 'hdfs://localhost:9000/edx-analytics-pipeline/warehouse'  \
--n-reduce-task $nreducetask \
--overwrite-n-days $overwritendays \
--mapreduce-engine "hadoop" \
--remote-log-level "DEBUG"



#function enrollmentsintomysql()
#{

#PYTHONPATH='/edx/app/hadoop/pipeline/local/lib/python2.7/site-packages/edx/analytics/tasks/insights' luigi --module enrollments $1 --interval-start $intervalstart --interval $interval --remote-log-level "DEBUG" --source '["hdfs://localhost:9000/data"]' --pattern $pattern --warehouse-path 'hdfs://localhost:9000/edx-analytics-pipeline/warehouse'  --overwrite-n-days $overwritendays --n-reduce-task $nreducetask --mapreduce-engine "hadoop" --overwrite 
#--expand-interval='0 w 2 d 0 h 0 m 0 s' \
#}


#2-run courseenrollment /event_export_by_course
function eventtask()
{
#PYTHONPATH='/edx/app/hadoop/pipeline/local/lib/python2.7/site-packages/edx/analytics/tasks/insights' luigi   --module enrollments $1 --interval '2019-05-01-2019-05-04' --source '["hdfs://localhost:9000/data/"]' --pattern '[".*tracking.log.*"]' --warehouse-path 'hdfs://localhost:9000/edx-analytics-pipeline/warehouse'  --n-reduce-task "1" --overwrite-n-days "2" --mapreduce-engine "hadoop" --remote-log-level "DEBUG" --output-root hdfs://localhost:9000/edx-analytics-pipeline/course_enrollment
PYTHONPATH='/edx/app/hadoop/pipeline/local/lib/python2.7/site-packages/edx/analytics/tasks/insights' luigi   --module enrollments $1 --interval $interval --source '["hdfs://localhost:9000/data/"]' --pattern $pattern --warehouse-path 'hdfs://localhost:9000/edx-analytics-pipeline/warehouse'  --n-reduce-task $nreducetask --overwrite-n-days $overwritendays --mapreduce-engine "hadoop" --remote-log-level "DEBUG" --output-root hdfs://localhost:9000/edx-analytics-pipeline/event-export-by-course/output/
}


#1-for test warehouse loading warehouse/course_enrollment_events
function courseenrollmenteventtask()
{
PYTHONPATH='/edx/app/hadoop/pipeline/local/lib/python2.7/site-packages/edx/analytics/tasks/insights' luigi --module enrollments $1 --source '["hdfs://localhost:9000/data/"]' --pattern $pattern --warehouse-path 'hdfs://localhost:9000/edx-analytics-pipeline/warehouse' --interval $interval  --n-reduce-task $nreducetask
}


#3-courseenrollment hive table
function courseenrollmenttabletask()
{
PYTHONPATH='/edx/app/hadoop/pipeline/local/lib/python2.7/site-packages/edx/analytics/tasks/insights' luigi --module enrollments $1 --warehouse-path 'hdfs://localhost:9000/edx-analytics-pipeline/warehouse/course_enrollment' 
}

#4 - coureenrollmentPartitiontask
function courseenrollmentpartitiontask()
{
PYTHONPATH='/edx/app/hadoop/pipeline/local/lib/python2.7/site-packages/edx/analytics/tasks/insights' luigi --module enrollments $1 --warehouse-path 'hdfs://localhost:9000/edx-analytics-pipeline/warehouse' --overwrite-n-days $overwritendays
}

function coursemetasummary()
{
PYTHONPATH='/edx/app/hadoop/pipeline/local/lib/python2.7/site-packages/edx/analytics/tasks/insights' luigi --module enrollments $1  --interval $interval --source '["hdfs://localhost:9000/data"]' --pattern $pattern --warehouse-path 'hdfs://localhost:9000/edx-analytics-pipeline/warehouse'  --n-reduce-task $nreducetask --overwrite-n-days $overwritendays --mapreduce-engine "hadoop" --remote-log-level "DEBUG"
}


function pathselection()
{
PYTHONPATH='/edx/app/hadoop/pipeline/local/lib/python2.7/site-packages/edx/analytics/tasks/insights' luigi --module enrollments $1 --source '["hdfs://localhost:9000/data"]' --pattern $pattern --warehouse-path 'hdfs://localhost:9000/edx-analytics-pipeline/warehouse' --interval $interval  --n-reduce-task nreducetask --overwrite-n-days overwritendays --mapreduce-engine "hadoop" --remote-log-level "DEBUG" --output-root hdfs://localhost:9000/edx-analytics-pipeline/event-export-by-course/output/
#--expand-interval='0 w 2 d 0 h 0 m 0 s' 
}

#enrollmentsintomysql ImportEnrollmentsIntoMysql
#coursemetasummary CourseMetaSummaryEnrollmentIntoMysql
#eventtask CourseEnrollmentTask

#8courseenrollmenteventtask CourseEnrollmentEventsTask
#courseenrollmenttabletask CourseEnrollmentTableTask
#courseenrollmentpartitiontask CourseEnrollmentPartitionTask
